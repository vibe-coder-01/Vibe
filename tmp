import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

def load_and_prepare_data(df):
    """
    Prepare the dataset for analysis
    """
    # Convert date column to datetime
    df['GMT Prod Yield Date'] = pd.to_datetime(df['GMT Prod Yield Date'])
    
    # Extract year and month for temporal analysis
    df['Year'] = df['GMT Prod Yield Date'].dt.year
    df['Month'] = df['GMT Prod Yield Date'].dt.month
    df['Year_Month'] = df['GMT Prod Yield Date'].dt.to_period('M')
    
    # Define target variables
    target_vars = ['Y1', 'Y2', 'Y3', 'Y4', 'Y5']
    
    return df, target_vars

def calculate_shift_metrics(df, target_vars):
    """
    Calculate comprehensive shift metrics for each product type
    """
    results = []
    
    for product in df['Merge'].unique():
        if pd.isna(product):
            continue
            
        product_data = df[df['Merge'] == product].copy()
        
        for target in target_vars:
            if target not in product_data.columns:
                continue
                
            # Remove missing values for calculations
            clean_data = product_data.dropna(subset=[target])
            
            if len(clean_data) < 10:  # Skip if insufficient data
                continue
            
            # Year-over-year analysis
            yearly_stats = clean_data.groupby('Year')[target].agg([
                'mean', 'median', 'std', 'count'
            ]).reset_index()
            
                # Calculate year-over-year changes with proper handling
                total_change = 0
                if len(yearly_stats) > 1:
                    yearly_stats['YoY_Mean_Change'] = yearly_stats['mean'].pct_change() * 100
                    yearly_stats['YoY_Median_Change'] = yearly_stats['median'].pct_change() * 100
                    
                    # Recent vs baseline comparison (last year vs first year)
                    recent_mean = yearly_stats['mean'].iloc[-1]
                    baseline_mean = yearly_stats['mean'].iloc[0]
                    
                    if not (pd.isna(recent_mean) or pd.isna(baseline_mean)) and baseline_mean != 0:
                        total_change = ((recent_mean - baseline_mean) / baseline_mean) * 100
                
                # Trend analysis using linear regression
                years = yearly_stats['Year'].values
                means = yearly_stats['mean'].values
                
                # Check for valid data before regression
                valid_mask = ~(np.isnan(years) | np.isnan(means) | np.isinf(years) | np.isinf(means))
                years_clean = years[valid_mask]
                means_clean = means[valid_mask]
                
                if len(years_clean) > 2 and len(means_clean) > 2:
                    try:
                        slope, intercept, r_value, p_value, std_err = stats.linregress(years_clean, means_clean)
                        trend_significance = 'Significant' if p_value < 0.05 else 'Not Significant'
                    except (ValueError, TypeError) as e:
                        slope, r_value, p_value, trend_significance = 0, 0, 1, 'Error in Calculation'
                else:
                    slope, r_value, p_value, trend_significance = 0, 0, 1, 'Insufficient Data'
                
                results.append({
                    'Product': product,
                    'Target_Variable': target,
                    'Analysis_Type': 'Year_over_Year',
                    'Total_Change_Pct': round(total_change, 2),
                    'Trend_Slope': round(slope, 4),
                    'Trend_R_Squared': round(r_value**2, 3),
                    'Trend_Significance': trend_significance,
                    'Years_Available': len(yearly_stats),
                    'Latest_Mean': round(recent_mean, 3),
                    'Baseline_Mean': round(baseline_mean, 3)
                })
    
    return pd.DataFrame(results)

def calculate_monthly_shifts(df, target_vars):
    """
    Calculate month-over-month shifts for recent periods
    """
    results = []
    
    # Focus on last 24 months for monthly analysis
    recent_date = df['GMT Prod Yield Date'].max()
    cutoff_date = recent_date - pd.DateOffset(months=24)
    recent_df = df[df['GMT Prod Yield Date'] >= cutoff_date].copy()
    
    for product in recent_df['Merge'].unique():
        if pd.isna(product):
            continue
            
        product_data = recent_df[recent_df['Merge'] == product].copy()
        
        for target in target_vars:
            if target not in product_data.columns:
                continue
                
            clean_data = product_data.dropna(subset=[target])
            
            if len(clean_data) < 6:  # Need at least 6 months
                continue
            
            # Monthly aggregation
            monthly_stats = clean_data.groupby('Year_Month')[target].agg([
                'mean', 'median', 'count'
            ]).reset_index()
            
            if len(monthly_stats) > 3:
                # Calculate rolling 3-month changes
                monthly_stats['Rolling_3M_Change'] = monthly_stats['mean'].pct_change(periods=3) * 100
                
                # Recent trend (last 6 months)
                if len(monthly_stats) >= 6:
                    recent_6m = monthly_stats.tail(6)
                    months_num = np.arange(len(recent_6m))
                    means = recent_6m['mean'].values
                    
                    # Clean data for regression
                    valid_mask = ~(np.isnan(means) | np.isinf(means))
                    months_clean = months_num[valid_mask]
                    means_clean = means[valid_mask]
                    
                    if len(means_clean) > 2:
                        try:
                            slope, _, r_value, p_value, _ = stats.linregress(months_clean, means_clean)
                            trend_significance = 'Significant' if p_value < 0.05 else 'Not Significant'
                        except (ValueError, TypeError):
                            slope, r_value, p_value, trend_significance = 0, 0, 1, 'Error in Calculation'
                    else:
                        slope, r_value, p_value, trend_significance = 0, 0, 1, 'Insufficient Data'
    
    return pd.DataFrame(results)

def create_shift_summary(yearly_df, monthly_df):
    """
    Create a comprehensive summary of shifts by product and target
    """
    # Merge yearly and monthly results
    summary = yearly_df.merge(
        monthly_df, 
        on=['Product', 'Target_Variable'], 
        how='outer'
    )
    
    # Create shift severity categories
    def categorize_shift(row):
        total_change = abs(row.get('Total_Change_Pct', 0))
        trend_sig = row.get('Trend_Significance', 'Not Significant')
        recent_sig = row.get('Recent_6M_Significance', 'Not Significant')
        
        if total_change > 20 and trend_sig == 'Significant':
            return 'High Impact Shift'
        elif total_change > 10 and (trend_sig == 'Significant' or recent_sig == 'Significant'):
            return 'Medium Impact Shift'
        elif total_change > 5:
            return 'Low Impact Shift'
        else:
            return 'Stable'
    
    summary['Shift_Category'] = summary.apply(categorize_shift, axis=1)
    
    return summary

def create_trend_plots(df, target_vars):
    """
    Create comprehensive trend plots for yearly and monthly patterns
    """
    # Get top products by data availability and significance
    product_data_count = df.groupby('Merge').size().sort_values(ascending=False)
    top_products = product_data_count.head(8).index.tolist()  # Focus on top 8 products
    
    # Create the main trend visualization
    n_targets = len(target_vars)
    fig = plt.figure(figsize=(20, 4 * n_targets))
    
    # Color palette for products
    colors = plt.cm.Set3(np.linspace(0, 1, len(top_products)))
    
    for i, target in enumerate(target_vars):
        # Skip if target not in data
        if target not in df.columns:
            continue
            
        # Yearly trends subplot
        ax_yearly = plt.subplot(n_targets, 2, 2*i + 1)
        
        # Monthly trends subplot  
        ax_monthly = plt.subplot(n_targets, 2, 2*i + 2)
        
        product_count = 0
        legend_elements = []
        
        for j, product in enumerate(top_products):
            if pd.isna(product):
                continue
                
            product_data = df[df['Merge'] == product].copy()
            clean_data = product_data.dropna(subset=[target])
            
            if len(clean_data) < 5:  # Need minimum data points
                continue
                
            color = colors[j % len(colors)]
            
            # Yearly aggregation and plotting
            yearly_agg = clean_data.groupby('Year')[target].agg(['mean', 'count']).reset_index()
            yearly_agg = yearly_agg[yearly_agg['count'] >= 5]  # At least 5 data points per year
            
            if len(yearly_agg) > 1:
                ax_yearly.plot(yearly_agg['Year'], yearly_agg['mean'], 
                              marker='o', linewidth=2, color=color, alpha=0.8,
                              label=f'{product} (n={len(clean_data)})')
                product_count += 1
        
        # Format yearly plot
        ax_yearly.set_title(f'{target} - Yearly Trends', fontsize=12, fontweight='bold')
        ax_yearly.set_xlabel('Year')
        ax_yearly.set_ylabel(f'{target} (Annual Average)')
        ax_yearly.grid(True, alpha=0.3)
        ax_yearly.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)
        
        # Monthly trends (last 24 months)
        recent_date = df['GMT Prod Yield Date'].max()
        cutoff_date = recent_date - pd.DateOffset(months=24)
        recent_df = df[df['GMT Prod Yield Date'] >= cutoff_date].copy()
        
        for j, product in enumerate(top_products):
            if pd.isna(product):
                continue
                
            product_data = recent_df[recent_df['Merge'] == product].copy()
            clean_data = product_data.dropna(subset=[target])
            
            if len(clean_data) < 3:
                continue
                
            color = colors[j % len(colors)]
            
            # Monthly aggregation
            monthly_agg = clean_data.groupby('Year_Month')[target].agg(['mean', 'count']).reset_index()
            monthly_agg = monthly_agg[monthly_agg['count'] >= 2]  # At least 2 data points per month
            
            if len(monthly_agg) > 2:
                # Convert Period to datetime for plotting
                monthly_agg['Date'] = monthly_agg['Year_Month'].dt.to_timestamp()
                ax_monthly.plot(monthly_agg['Date'], monthly_agg['mean'], 
                               marker='s', linewidth=1.5, color=color, alpha=0.8,
                               markersize=4)
        
        # Format monthly plot
        ax_monthly.set_title(f'{target} - Monthly Trends (Last 24 Months)', fontsize=12, fontweight='bold')
        ax_monthly.set_xlabel('Month')
        ax_monthly.set_ylabel(f'{target} (Monthly Average)')
        ax_monthly.grid(True, alpha=0.3)
        ax_monthly.tick_params(axis='x', rotation=45)
        
        # Add trend lines for significant trends
        for j, product in enumerate(top_products[:5]):  # Show trend lines for top 5 products only
            if pd.isna(product):
                continue
                
            product_data = recent_df[recent_df['Merge'] == product].copy()
            clean_data = product_data.dropna(subset=[target])
            
            if len(clean_data) < 6:
                continue
                
            monthly_agg = clean_data.groupby('Year_Month')[target].mean().reset_index()
            if len(monthly_agg) > 3:
                x_vals = np.arange(len(monthly_agg))
                y_vals = monthly_agg[target].values
                
                # Clean data for trend line
                valid_mask = ~(np.isnan(y_vals) | np.isinf(y_vals))
                if np.sum(valid_mask) > 3:
                    try:
                        slope, intercept, r_val, p_val, _ = stats.linregress(x_vals[valid_mask], y_vals[valid_mask])
                        if p_val < 0.05:  # Significant trend
                            trend_line = slope * x_vals + intercept
                            dates = monthly_agg['Year_Month'].dt.to_timestamp()
                            ax_monthly.plot(dates, trend_line, '--', color=colors[j % len(colors)], 
                                          alpha=0.6, linewidth=1)
                    except:
                        continue
    
    plt.tight_layout()
    return fig

def create_product_comparison_plots(df, target_vars, summary_df):
    """
    Create focused comparison plots for products with significant shifts
    """
    # Identify products with high impact shifts
    high_impact_products = summary_df[
        summary_df['Shift_Category'].isin(['High Impact Shift', 'Medium Impact Shift'])
    ]['Product'].value_counts().head(6).index.tolist()
    
    if len(high_impact_products) == 0:
        return None
    
    # Create comparison plots
    fig, axes = plt.subplots(2, 3, figsize=(18, 10))
    fig.suptitle('High Impact Products - Detailed Comparison', fontsize=16, fontweight='bold')
    axes = axes.flatten()
    
    colors = plt.cm.Dark2(np.linspace(0, 1, len(target_vars)))
    
    for idx, product in enumerate(high_impact_products[:6]):
        ax = axes[idx]
        
        product_data = df[df['Merge'] == product].copy()
        
        # Plot all target variables for this product
        for t_idx, target in enumerate(target_vars):
            if target not in product_data.columns:
                continue
                
            clean_data = product_data.dropna(subset=[target])
            if len(clean_data) < 5:
                continue
            
            # Yearly trend
            yearly_trend = clean_data.groupby('Year')[target].mean().reset_index()
            if len(yearly_trend) > 1:
                ax.plot(yearly_trend['Year'], yearly_trend[target], 
                       marker='o', linewidth=2, color=colors[t_idx], 
                       label=target, alpha=0.8)
        
        ax.set_title(f'{product}', fontsize=11, fontweight='bold')
        ax.set_xlabel('Year')
        ax.set_ylabel('Target Variable Value')
        ax.grid(True, alpha=0.3)
        ax.legend(fontsize=8)
        
        # Add annotations for significant changes
        product_summary = summary_df[summary_df['Product'] == product]
        if len(product_summary) > 0:
            max_change = product_summary['Total_Change_Pct'].abs().max()
            ax.text(0.02, 0.98, f'Max Change: {max_change:.1f}%', 
                   transform=ax.transAxes, fontsize=9, 
                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),
                   verticalalignment='top')
    
    # Hide empty subplots
    for idx in range(len(high_impact_products), 6):
        axes[idx].set_visible(False)
    
    plt.tight_layout()
    return fig

def visualize_shifts(df, target_vars, summary_df):
    """
    Create comprehensive visualizations for target variable shifts
    """
    # Set up the plotting style
    plt.style.use('default')
    sns.set_palette("husl")
    
    # 1. Overview Dashboard
    fig_overview, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig_overview.suptitle('Target Variable Shift Analysis - Overview Dashboard', fontsize=16, fontweight='bold')
    
    # Heatmap of total percentage changes
    pivot_data = summary_df.pivot(index='Product', columns='Target_Variable', values='Total_Change_Pct')
    sns.heatmap(pivot_data, annot=True, cmap='RdYlBu_r', center=0, 
                ax=axes[0,0], fmt='.1f', cbar_kws={'label': 'Total Change %'})
    axes[0,0].set_title('Total Change % by Product and Target (YoY)')
    axes[0,0].set_xlabel('')
    
    # Shift category distribution
    shift_counts = summary_df['Shift_Category'].value_counts()
    axes[0,1].pie(shift_counts.values, labels=shift_counts.index, autopct='%1.1f%%', startangle=90)
    axes[0,1].set_title('Distribution of Shift Categories')
    
    # Top products with highest variability
    product_variability = summary_df.groupby('Product')['Total_Change_Pct'].apply(
        lambda x: np.sqrt(np.mean(x**2))  # RMS of changes
    ).sort_values(ascending=False).head(10)
    
    product_variability.plot(kind='barh', ax=axes[1,0])
    axes[1,0].set_title('Top 10 Products by Variability (RMS of Changes)')
    axes[1,0].set_xlabel('RMS of Total Changes %')
    
    # Trend significance by target variable
    if 'Trend_Significance' in summary_df.columns:
        sig_counts = summary_df.groupby(['Target_Variable', 'Trend_Significance']).size().unstack(fill_value=0)
        sig_counts.plot(kind='bar', ax=axes[1,1], stacked=True)
        axes[1,1].set_title('Trend Significance by Target Variable')
        axes[1,1].set_xlabel('Target Variables')
        axes[1,1].set_ylabel('Count of Products')
        axes[1,1].legend(title='Significance')
        axes[1,1].tick_params(axis='x', rotation=0)
    
    plt.tight_layout()
    
    # 2. Create detailed trend plots
    fig_trends = create_trend_plots(df, target_vars)
    
    # 3. Create product comparison plots
    fig_comparison = create_product_comparison_plots(df, target_vars, summary_df)
    
    return fig_overview, fig_trends, fig_comparison

def generate_insights_report(summary_df):
    """
    Generate key insights from the analysis
    """
    insights = []
    
    # Overall statistics
    total_combinations = len(summary_df)
    high_impact = len(summary_df[summary_df['Shift_Category'] == 'High Impact Shift'])
    medium_impact = len(summary_df[summary_df['Shift_Category'] == 'Medium Impact Shift'])
    
    insights.append(f"EXECUTIVE SUMMARY:")
    insights.append(f"- Analyzed {total_combinations} product-target combinations")
    insights.append(f"- {high_impact} combinations show HIGH IMPACT shifts (>20% change)")
    insights.append(f"- {medium_impact} combinations show MEDIUM IMPACT shifts (10-20% change)")
    
    # Most problematic products
    if high_impact > 0:
        high_impact_products = summary_df[summary_df['Shift_Category'] == 'High Impact Shift']['Product'].value_counts()
        insights.append(f"\nMOST PROBLEMATIC PRODUCTS:")
        for product, count in high_impact_products.head(3).items():
            insights.append(f"- {product}: {count} high-impact target variables")
    
    # Most affected target variables
    target_impact = summary_df[summary_df['Shift_Category'].isin(['High Impact Shift', 'Medium Impact Shift'])]['Target_Variable'].value_counts()
    if len(target_impact) > 0:
        insights.append(f"\nMOST AFFECTED TARGET VARIABLES:")
        for target, count in target_impact.head(3).items():
            insights.append(f"- {target}: {count} products showing significant shifts")
    
    # Recent trend concerns
    recent_concerns = summary_df[summary_df['Recent_6M_Significance'] == 'Significant']
    if len(recent_concerns) > 0:
        insights.append(f"\nRECENT TREND CONCERNS (Last 6 months):")
        insights.append(f"- {len(recent_concerns)} combinations showing significant recent deterioration")
        
        # Top recent concerns
        recent_top = recent_concerns.nlargest(3, 'Latest_3M_Avg_Change')[['Product', 'Target_Variable', 'Latest_3M_Avg_Change']]
        for _, row in recent_top.iterrows():
            insights.append(f"  • {row['Product']} - {row['Target_Variable']}: {row['Latest_3M_Avg_Change']:.1f}% change")
    
    return "\n".join(insights)

def main_analysis(df):
    """
    Main analysis function
    """
    print("🔍 MACHINE UTILIZATION & OEE TARGET VARIABLE SHIFT ANALYSIS")
    print("="*70)
    
    # Prepare data
    df_prep, target_vars = load_and_prepare_data(df)
    
    print(f"📊 Dataset Overview:")
    print(f"- Date range: {df_prep['GMT Prod Yield Date'].min()} to {df_prep['GMT Prod Yield Date'].max()}")
    print(f"- Total records: {len(df_prep):,}")
    print(f"- Unique products: {df_prep['Merge'].nunique()}")
    print(f"- Target variables: {target_vars}")
    
    # Calculate shifts
    print("\n⚙️  Calculating year-over-year shifts...")
    yearly_shifts = calculate_shift_metrics(df_prep, target_vars)
    
    print("⚙️  Calculating month-over-month shifts...")
    monthly_shifts = calculate_monthly_shifts(df_prep, target_vars)
    
    # Create comprehensive summary
    summary = create_shift_summary(yearly_shifts, monthly_shifts)
    
    # Generate insights
    insights = generate_insights_report(summary)
    
    # Create visualizations
    print("📈 Creating visualizations...")
    fig_overview, fig_trends, fig_comparison = visualize_shifts(df_prep, target_vars, summary)
    
    print("\n📈 KEY INSIGHTS:")
    print(insights)
    
    print("\n📋 DETAILED RESULTS:")
    print("\nTop 10 Combinations by Impact:")
    if len(summary) > 0:
        top_impacts = summary.nlargest(10, 'Total_Change_Pct')[
            ['Product', 'Target_Variable', 'Total_Change_Pct', 'Shift_Category', 'Trend_Significance']
        ]
        print(top_impacts.to_string(index=False))
    else:
        print("No significant shifts detected in the data.")
    
    # Display plots
    plt.show(fig_overview)
    if fig_trends:
        plt.show(fig_trends)
    if fig_comparison:
        plt.show(fig_comparison)
    
    return {
        'summary': summary,
        'insights': insights,
        'overview_plot': fig_overview,
        'trend_plots': fig_trends,
        'comparison_plots': fig_comparison
    }

# Usage example:
# results = main_analysis(your_dataframe)
# Access individual components:
# results['summary'] - detailed shift analysis
# results['trend_plots'] - yearly and monthly trend plots
# results['comparison_plots'] - focused high-impact product comparisons

print("✅ Target Variable Shift Analysis Module Ready!")
print("📝 Usage: summary, plot, insights = main_analysis(your_dataframe)")
print("🎯 Focus: Identifies shifts by product type affecting machine utilization")
